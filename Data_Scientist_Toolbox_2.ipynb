{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Scientist Toolbox 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Indrajeet90/Data-Scientist-with-Python/blob/master/Data_Scientist_Toolbox_2.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "VFon94Cx0ByO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Iterators"
      ]
    },
    {
      "metadata": {
        "id": "aDp3luKj0IKH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Iterators vs Iterables**\n",
        "\n",
        "Let's do a quick recall of what you've learned about iterables and iterators.An iterable is an object that can return an iterator, while an iterator is an object that keeps state and produces the next value when you call next() on it"
      ]
    },
    {
      "metadata": {
        "id": "DiaNOp5h1Z9W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Iterating over iterables**"
      ]
    },
    {
      "metadata": {
        "id": "OhUqb-U8sx7w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "6b7d58a1-6fd0-42a1-9bbc-6f1cefd8a4ad"
      },
      "cell_type": "code",
      "source": [
        "# Create a list of strings: flash\n",
        "flash = ['jay garrick', 'barry allen', 'wally west', 'bart allen']\n",
        "\n",
        "# Print each list item in flash using a for loop\n",
        "for person in flash:\n",
        "    print(person)\n",
        "\n",
        "\n",
        "# Create an iterator for flash: superspeed\n",
        "superspeed=iter(flash)    # using iter function to create an iterator\n",
        "\n",
        "# Print each item from the iterator\n",
        "print(next(superspeed))\n",
        "print(next(superspeed))\n",
        "print(next(superspeed))\n",
        "print(next(superspeed))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jay garrick\n",
            "barry allen\n",
            "wally west\n",
            "bart allen\n",
            "jay garrick\n",
            "barry allen\n",
            "wally west\n",
            "bart allen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iw4beKvM2va8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Recall that **range() **doesn't actually create the list; instead, it creates a range object with an iterator that produces the values until it reaches the limit (in the example, until the value 4). If range() created the actual list, calling it with a value of 10100 may not work, especially since a number as big as that may go over a regular computer's memory. The value 10100 is actually what's called a Googol which is a 1 followed by a hundred 0s. That's a huge number!\n",
        "\n",
        "Your task for this exercise is to show that calling **range()** with 10100 won't actually pre-create the list."
      ]
    },
    {
      "metadata": {
        "id": "j3M2J6WC2wPk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "aea3f3ed-b342-4592-85cd-a4734003bb87"
      },
      "cell_type": "code",
      "source": [
        "# Create an iterator for range(3): small_value\n",
        "small_value = iter(range(3))\n",
        "\n",
        "# Print the values in small_value\n",
        "print(next(small_value))\n",
        "print(next(small_value))\n",
        "print(next(small_value))\n",
        "\n",
        "# Loop over range(3) and print the values\n",
        "for num in range(3):\n",
        "    print(num)\n",
        "\n",
        "\n",
        "# Create an iterator for range(10 ** 100): googol\n",
        "googol = iter(range(10**100))\n",
        "\n",
        "# Print the first 5 values from googol\n",
        "print(next(googol))\n",
        "print(next(googol))\n",
        "print(next(googol))\n",
        "print(next(googol))\n",
        "print(next(googol))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_WiLkald3iFU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Iterators as function arguments**\n",
        "\n",
        "You've been using the **iter()** function to get an iterator object, as well as the **next()** function to retrieve the values one by one from the iterator object.\n",
        "\n",
        "There are also functions that take iterators as arguments. For example, the **list() **and **sum() **functions return a list and the sum of elements, respectively."
      ]
    },
    {
      "metadata": {
        "id": "h84Knw0k3VzQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a56cf27b-7dc7-4167-fc5c-4ac29c510024"
      },
      "cell_type": "code",
      "source": [
        "# Create a range object: values\n",
        "values = range(10,21)\n",
        "\n",
        "# Print the range object\n",
        "print(values)\n",
        "\n",
        "# Create a list of integers: values_list\n",
        "values_list = list(values)\n",
        "\n",
        "# Print values_list\n",
        "print(values_list)\n",
        "\n",
        "# Get the sum of values: values_sum\n",
        "values_sum = sum(values)\n",
        "\n",
        "# Print values_sum\n",
        "print(values_sum)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "range(10, 21)\n",
            "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "165\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v3Ly8kKa4kCZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Using enumerate**\n",
        "\n",
        "You've just gained several new ideas on iterators from the last video and one of them is the **enumerate()** function. Recall that e**numerate()** returns an enumerate object that produces a sequence of tuples, and each of the tuples is an index-value pair."
      ]
    },
    {
      "metadata": {
        "id": "IeUBN-MC4o2v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "18e155e0-5f4f-492e-d99f-846d25f244b5"
      },
      "cell_type": "code",
      "source": [
        "# Create a list of strings: mutants\n",
        "mutants = ['charles xavier', \n",
        "            'bobby drake', \n",
        "            'kurt wagner', \n",
        "            'max eisenhardt', \n",
        "            'kitty pryde']\n",
        "\n",
        "# Create a list of tuples: mutant_list\n",
        "mutant_list = list(enumerate(mutants))\n",
        "\n",
        "# Print the list of tuples\n",
        "print(mutant_list)\n",
        "\n",
        "# Unpack and print the tuple pairs\n",
        "for index1,value1 in enumerate(mutants):\n",
        "    print(index1, value1)\n",
        "\n",
        "# Change the start index\n",
        "for index2,value2 in enumerate(mutants, start=1):\n",
        "    print(index2, value2)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 'charles xavier'), (1, 'bobby drake'), (2, 'kurt wagner'), (3, 'max eisenhardt'), (4, 'kitty pryde')]\n",
            "0 charles xavier\n",
            "1 bobby drake\n",
            "2 kurt wagner\n",
            "3 max eisenhardt\n",
            "4 kitty pryde\n",
            "1 charles xavier\n",
            "2 bobby drake\n",
            "3 kurt wagner\n",
            "4 max eisenhardt\n",
            "5 kitty pryde\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YNDjQcFS55qP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Using zip**\n",
        "\n",
        "Another interesting function that you've learned is **zip(),** which takes any number of iterables and returns a zip object that is an iterator of tuples. If you wanted to print the values of a zip object, you can convert it into a list and then print it. Printing just a zip object will not return the values unless you unpack it first. In this exercise, you will explore this for yourself."
      ]
    },
    {
      "metadata": {
        "id": "e6bpVQ4U59et",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a list of tuples: mutant_data\n",
        "mutant_data = list(zip(mutants,aliases,powers))\n",
        "\n",
        "# Print the list of tuples\n",
        "print(mutant_data)\n",
        "\n",
        "# Create a zip object using the three lists: mutant_zip\n",
        "mutant_zip = zip(mutants,aliases,powers)\n",
        "\n",
        "# Print the zip object\n",
        "print(mutant_zip)\n",
        "\n",
        "# Unpack the zip object and print the tuple values\n",
        "for value1,value2,value3 in mutant_zip:\n",
        "    print(value1, value2, value3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pWrcl1_8Aw1o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " **Using * and zip to 'unzip'**\n",
        "\n",
        "Let's play around with** zip() **a little more. There is no unzip function for doing the reverse of what **zip()** does. We can, however, reverse what has been zipped together by using **zip() **with a little help from *! * unpacks an iterable such as a list or a tuple into positional arguments in a function call."
      ]
    },
    {
      "metadata": {
        "id": "v6Qaq4h4A_kQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a zip object from mutants and powers: z1\n",
        "z1 = zip(mutants,powers)\n",
        "\n",
        "# Print the tuples in z1 by unpacking with *\n",
        "print(*z1)\n",
        "\n",
        "# Re-create a zip object from mutants and powers: z1\n",
        "z1 = zip(mutants,powers)\n",
        "\n",
        "# 'Unzip' the tuples in z1 by unpacking with * and zip(): result1, result2\n",
        "result1, result2 = zip(*z1)\n",
        "\n",
        "# Check if unpacked tuples are equivalent to original tuples\n",
        "print(result1 == mutants)\n",
        "print(result2 == powers)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zInEoLOEBfpO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Using iterators to load large files into memory"
      ]
    },
    {
      "metadata": {
        "id": "QWmntfAJB2Fp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Processing large amounts of Twitter data**\n",
        "\n",
        "Sometimes, the data we have to process reaches a size that is too much for a computer's memory to handle. This is a common problem faced by data scientists. A solution to this is to process an entire data source chunk by chunk, instead of a single go all at once.\n",
        "\n",
        "In this exercise, you will do just that. You will process a large csv file of Twitter data in the same way that you processed 'tweets.csv' in Bringing it all together exercises of the prequel course, but this time, working on it in chunks of 10 entries at a time."
      ]
    },
    {
      "metadata": {
        "id": "kv0XPHn7Cxk7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initialize an empty dictionary: counts_dict\n",
        "counts_dict={}\n",
        "\n",
        "# Iterate over the file chunk by chunk\n",
        "for chunk in pd.read_csv('tweets.csv',chunksize=10):\n",
        "\n",
        "    # Iterate over the column in DataFrame\n",
        "    for entry in chunk['lang']:\n",
        "        if entry in counts_dict.keys():\n",
        "            counts_dict[entry] += 1\n",
        "        else:\n",
        "            counts_dict[entry] = 1\n",
        "\n",
        "# Print the populated dictionary\n",
        "print(counts_dict)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "82nprptmD6dj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Extracting information for large amounts of Twitter data**\n",
        "\n",
        "Great job chunking out that file in the previous exercise. You now know how to deal with situations where you need to process a very large file and that's a very useful skill to have!\n",
        "\n",
        "It's good to know how to process a file in smaller, more manageable chunks, but it can become very tedious having to write and rewrite the same code for the same task each time. In this exercise, you will be making your code more reusable by putting your work in the last exercise in a function definition."
      ]
    },
    {
      "metadata": {
        "id": "GvaT9YHmD8Ze",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Creating custom function for extracting large amount of data\n",
        "# Define count_entries()\n",
        "def count_entries(csv_file,c_size,colname):\n",
        "    \"\"\"Return a dictionary with counts of\n",
        "    occurrences as value for each key.\"\"\"\n",
        "    \n",
        "    # Initialize an empty dictionary: counts_dict\n",
        "    counts_dict = {}\n",
        "\n",
        "    # Iterate over the file chunk by chunk\n",
        "    for chunk in pd.read_csv(csv_file,chunksize=c_size):\n",
        "\n",
        "        # Iterate over the column in DataFrame\n",
        "        for entry in chunk[colname]:\n",
        "            if entry in counts_dict.keys():\n",
        "                counts_dict[entry] += 1\n",
        "            else:\n",
        "                counts_dict[entry] = 1\n",
        "\n",
        "    # Return counts_dict\n",
        "    return counts_dict\n",
        "\n",
        "# Call count_entries(): result_counts\n",
        "result_counts = count_entries('tweets.csv',10,'lang')\n",
        "\n",
        "# Print result_counts\n",
        "print(result_counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pkeXbFrrF0cR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# List comprehensions\n"
      ]
    },
    {
      "metadata": {
        "id": "eNHcUiQTF1uu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Write a basic list comprehension**\n",
        "\n",
        "In this exercise, you will practice what you've learned from the video about writing list comprehensions. You will write a list comprehension and identify the output that will be produced.\n",
        "\n",
        "The following list has been pre-loaded in the environment.\n",
        "\n",
        "doctor = ['house', 'cuddy', 'chase', 'thirteen', 'wilson']"
      ]
    },
    {
      "metadata": {
        "id": "AhLzXa-QIk8C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de781e0d-e34d-4ed0-d794-f95f6284ca7e"
      },
      "cell_type": "code",
      "source": [
        "doctor = ['house', 'cuddy', 'chase', 'thirteen', 'wilson']\n",
        "[doc[0] for doc in doctor]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['h', 'c', 'c', 't', 'w']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "6Zd3_llAJCcJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**List comprehension over iterables**\n",
        "\n",
        "You know that list comprehensions can be built over iterables. Given the following objects below, which of these can we build list comprehensions over?\n",
        "\n",
        "**doctor** = ['house', 'cuddy', 'chase', 'thirteen', 'wilson']\n",
        "\n",
        "**range(50)**\n",
        "\n",
        "**underwood** = 'After all, we are nothing more or less than what we choose to reveal.'\n",
        "\n",
        "**jean **= '24601'\n",
        "\n",
        "**flash** = ['jay garrick', 'barry allen', 'wally west', 'bart allen']\n",
        "\n",
        "**valjean** = 24601\n",
        "\n",
        "You can build list comprehensions over all the objects except the integer object **valjean**"
      ]
    },
    {
      "metadata": {
        "id": "u5vhoEjaJiiP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Writing list comprehensions**\n",
        "\n",
        "You now have all the knowledge necessary to begin writing list comprehensions! Your job in this exercise is to write a list comprehension that produces a list of the squares of the numbers ranging from** 0 to 9.**"
      ]
    },
    {
      "metadata": {
        "id": "Nkp8BdH6JFmQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create list comprehension: squares\n",
        "squares = [(i**2) for i in range(0,10)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y0XiLVPgKK5W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Nested list comprehensions**\n",
        "\n",
        " In this exercise, you will be writing a list comprehension within another list comprehension, or nested list comprehensions. It sounds a little tricky, but you can do it!\n",
        "\n",
        "Let's step aside for a while from strings. One of the ways in which lists can be used are in representing multi-dimension objects such as matrices. Matrices can be represented as a list of lists in Python. For example a 5 x 5 matrix with values 0 to 4 in each row can be written as:\n",
        "\n",
        "**matrix =  **\n",
        "[[0, 1, 2, 3, 4],  \n",
        "                 [0, 1, 2, 3, 4],   \n",
        "          [0, 1, 2, 3, 4],  \n",
        "          [0, 1, 2, 3, 4],   \n",
        "          [0, 1, 2, 3, 4]]   \n",
        "\n",
        "To create the list of lists, you simply have to supply the list comprehension as the **output expression** of the overall list comprehension:\n",
        "\n",
        "*[[output expression] for iterator variable in iterable]*\n",
        "\n",
        "Note that here, the **output expression** is itself a list comprehension."
      ]
    },
    {
      "metadata": {
        "id": "GCB6TKZJKxIh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "29b2b7c3-64f9-4c47-a783-724d1065f2dd"
      },
      "cell_type": "code",
      "source": [
        "# Create a 5 x 5 matrix using a list of lists: matrix\n",
        "matrix = [[col for col in range(5)] for row in range(5)]\n",
        "\n",
        "# Print the matrix\n",
        "for row in matrix:\n",
        "    print(row)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4]\n",
            "[0, 1, 2, 3, 4]\n",
            "[0, 1, 2, 3, 4]\n",
            "[0, 1, 2, 3, 4]\n",
            "[0, 1, 2, 3, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3mGrGDOQLxzm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Advanced comprehensions\n"
      ]
    },
    {
      "metadata": {
        "id": "n0N8xXQ1Lz88",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Using conditionals in comprehensions**\n",
        "\n",
        "An interesting mechanism in list comprehensions is that you can also create lists with values that meet only a certain condition. One way of doing this is by using conditionals on iterator variables. In this exercise, you will do exactly that!\n",
        "\n",
        "You can apply a conditional statement to test the iterator variable by adding an if statement in the optional predicate expression part after the for statement in the comprehension:\n",
        "\n",
        "***[ output expression for iterator variable in iterable if predicate expression ].***"
      ]
    },
    {
      "metadata": {
        "id": "ka8HaFlAMN7R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00b485af-5656-4400-d9e7-02d4efd9b82d"
      },
      "cell_type": "code",
      "source": [
        "# Create a list of strings: fellowship\n",
        "fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']\n",
        "\n",
        "# Create list comprehension: new_fellowship\n",
        "new_fellowship = [member for member in fellowship if len(member)>6]\n",
        "\n",
        "# Print the new list\n",
        "print(new_fellowship)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['samwise', 'aragorn', 'legolas', 'boromir']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rqQ6Xq-tM9Vf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You will work on the same list, fellowship and, using a list comprehension and an **if-else **conditional statement in the output expression, create a list that keeps members of fellowship with 7 or more characters and replaces others with an empty string."
      ]
    },
    {
      "metadata": {
        "id": "-UpEjusnM_dY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0099d089-3e4f-43cf-bd98-017885c17c74"
      },
      "cell_type": "code",
      "source": [
        "# Create a list of strings: fellowship\n",
        "fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']\n",
        "\n",
        "# Create list comprehension: new_fellowship\n",
        "new_fellowship = [member if len(member) >= 7 else '' for member in fellowship]\n",
        "\n",
        "# Print the new list\n",
        "print(new_fellowship)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', 'samwise', '', 'aragorn', 'legolas', 'boromir', '']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o6Ega9NyIyRK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Dict comprehensions**\n",
        "\n",
        "There are many other objects you can build using comprehensions, such as dictionaries, pervasive objects in Data Science. You will create a dictionary using the comprehension syntax for this exercise. In this case, the comprehension is called a dict comprehension."
      ]
    },
    {
      "metadata": {
        "id": "9rT4HPdqI5E6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e665e68-e97d-4459-ed1a-826c1c88110c"
      },
      "cell_type": "code",
      "source": [
        "# Create a list of strings: fellowship\n",
        "fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']\n",
        "\n",
        "# Create dict comprehension: new_fellowship\n",
        "new_fellowship = { member:len(member) for member in fellowship }\n",
        "\n",
        "# Print the new list\n",
        "print(new_fellowship)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'frodo': 5, 'samwise': 7, 'merry': 5, 'aragorn': 7, 'legolas': 7, 'boromir': 7, 'gimli': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U9Xr7jcHJ76z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Introduction to generator expressions\n"
      ]
    },
    {
      "metadata": {
        "id": "_zU7DgVCJ9Ng",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "List comprehensions vs generators\n",
        "List comprehensions and generator expressions look very similar in their syntax, except for the use of parentheses () in generator expressions and brackets [] in list comprehensions.\n",
        "\n",
        "In this exercise, you will recall the difference between list comprehensions and generators. To help with that task, the following code has been pre-loaded in the environment:\n",
        "\n",
        "**List of strings**  \n",
        "fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']\n",
        "\n",
        "**List comprehension**  \n",
        "fellow1 = [member for member in fellowship if len(member) >= 7]\n",
        "\n",
        "**Generator expression** \n",
        "fellow2 = (member for member in fellowship if len(member) >= 7)"
      ]
    },
    {
      "metadata": {
        "id": "9vvdSHH5K8Pa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Write your own generator expressions**\n",
        "\n",
        "Recall that generator expressions basically have the same syntax as list comprehensions, except that it uses parentheses () instead of brackets []; this should make things feel familiar! Furthermore, if you have ever iterated over a dictionary with .items(), or used the range() function, for example, you have already encountered and used generators before, without knowing it! When you use these functions, Python creates generators for you behind the scenes"
      ]
    },
    {
      "metadata": {
        "id": "hgGuBBYAK0le",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "5c0ca81e-8d45-4db7-e8f4-2e95bb8af1cc"
      },
      "cell_type": "code",
      "source": [
        "# Create generator object: result\n",
        "result = (num for num in range(0,31))\n",
        "\n",
        "# Print the first 5 values\n",
        "print(next(result))\n",
        "print(next(result))\n",
        "print(next(result))\n",
        "print(next(result))\n",
        "print(next(result))\n",
        "\n",
        "# Print the rest of the values\n",
        "for value in result:\n",
        "    print(value)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jcNXBrOyL2ar",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Changing the output in generator expressions**\n",
        "\n",
        "In this exercise, you will push this idea a little further by adding to the output expression of a generator expression."
      ]
    },
    {
      "metadata": {
        "id": "bX58LSNcL-oc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "20884366-7a7d-460f-ecb5-795c313206c5"
      },
      "cell_type": "code",
      "source": [
        "# Create a list of strings: lannister\n",
        "lannister = ['cersei', 'jaime', 'tywin', 'tyrion', 'joffrey']\n",
        "\n",
        "# Create a generator object: lengths\n",
        "lengths = (len(person) for person in lannister)\n",
        "\n",
        "# Iterate over and print the values in lengths\n",
        "for value in lengths:\n",
        "    print(value)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "5\n",
            "5\n",
            "6\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oExP1nvrMa_F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Build a generator**\n",
        "\n",
        "Now, recall that not only are there generator expressions, there are generator functions as well. **Generator functions** are functions that, like generator expressions, yield a series of values, instead of returning a single value. A generator function is defined as you do a regular function, but whenever it generates a value, it uses the keyword yield instead of return.\n",
        "\n",
        "In this exercise, you will create a generator function with a similar mechanism as the generator expression you defined in the previous exercise:\n",
        "\n",
        "*lengths = (len(person) for person in lannister)*"
      ]
    },
    {
      "metadata": {
        "id": "LRvhnq2YMjmM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d0fb3abc-26d5-46b5-b5ec-27bd0d6af72b"
      },
      "cell_type": "code",
      "source": [
        "# Create a list of strings\n",
        "lannister = ['cersei', 'jaime', 'tywin', 'tyrion', 'joffrey']\n",
        "\n",
        "# Define generator function get_lengths\n",
        "def get_lengths(input_list):\n",
        "    \"\"\"Generator function that yields the\n",
        "    length of the strings in input_list.\"\"\"\n",
        "\n",
        "    # Yield the length of a string\n",
        "    for person in input_list:\n",
        "        yield len(person)\n",
        "\n",
        "# Print the values generated by get_lengths()\n",
        "for value in get_lengths(lannister):\n",
        "    print(value)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "5\n",
            "5\n",
            "6\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MMfrZIbhNkZe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**List comprehensions for time-stamped data**\n",
        "\n",
        "You will also be introduced to a data structure, the pandas Series, in this exercise. We won't elaborate on it much here, but what you should know is that it is a data structure that you will be working with a lot of times when analyzing data from pandas DataFrames. You can think of DataFrame columns as single-dimension arrays called Series."
      ]
    },
    {
      "metadata": {
        "id": "c-AtRQd8NpAs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Extract the created_at column from df: tweet_time\n",
        "tweet_time = df['created_at']\n",
        "\n",
        "# Extract the clock time: tweet_clock_time\n",
        "tweet_clock_time = [entry[11:19] for entry in tweet_time]\n",
        "\n",
        "# Print the extracted times\n",
        "print(tweet_clock_time)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6HQddFkCOVnn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Conditional list comprehensions for time-stamped data**\n",
        "\n",
        "Let's tweak your work further by adding a conditional that further specifies which entries to select.\n",
        "\n",
        "In this exercise, you will be using a list comprehension to extract the time from time-stamped Twitter data. You will add a conditional expression to the list comprehension so that you only select the times in which entry[17:19] is equal to '19'."
      ]
    },
    {
      "metadata": {
        "id": "2cQCBf4VObZ-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Extract the created_at column from df: tweet_time\n",
        "tweet_time = df['created_at']\n",
        "\n",
        "# Extract the clock time: tweet_clock_time\n",
        "tweet_clock_time = [entry[11:19] for entry in tweet_time if entry[17:19] == '19']\n",
        "\n",
        "# Print the extracted times\n",
        "print(tweet_clock_time)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dernbA2VOvj2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# World Bank Data"
      ]
    },
    {
      "metadata": {
        "id": "1i3R-tkcHct8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Dictionaries for data science**\n",
        "\n",
        "For this exercise, you'll use what you've learned about the** zip() **function and combine two lists into a dictionary.\n",
        "\n",
        "These lists are actually extracted from a **bigger dataset file of world development indicators from the World Bank.** For pedagogical purposes, we have pre-processed this dataset into the lists that you'll be working with.\n",
        "\n",
        "The first list **feature_names** contains header names of the dataset and the second list **row_vals** contains actual values of a row from the dataset, corresponding to each of the header names."
      ]
    },
    {
      "metadata": {
        "id": "8m6BArquH7DQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Zip lists: zipped_lists\n",
        "zipped_lists = zip(feature_names,row_vals)\n",
        "\n",
        "# Create a dictionary: rs_dict\n",
        "rs_dict = dict(zipped_lists)\n",
        "\n",
        "# Print the dictionary\n",
        "print(rs_dict)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wxjc4OmGIPhm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Writing a function to help you**\n",
        "\n",
        "Suppose you needed to repeat the same process done in the previous exercise to many, many rows of data. Rewriting your code again and again could become very tedious, repetitive, and unmaintainable.\n",
        "\n",
        "In this exercise, you will create a function to house the code you wrote earlier to make things easier and much more concise.  This way, you only need to call the function and supply the appropriate lists to create your dictionaries! Again, the lists feature_names and row_vals are preloaded and these contain the header names of the dataset and actual values of a row from the dataset, respectively."
      ]
    },
    {
      "metadata": {
        "id": "a_6axv86IURM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define lists2dict()\n",
        "def lists2dict(list1, list2):\n",
        "    \"\"\"Return a dictionary where list1 provides\n",
        "    the keys and list2 provides the values.\"\"\"\n",
        "\n",
        "    # Zip lists: zipped_lists\n",
        "    zipped_lists = zip(list1, list2)\n",
        "\n",
        "    # Create a dictionary: rs_dict\n",
        "    rs_dict = dict(zipped_lists)\n",
        "\n",
        "    # Return the dictionary\n",
        "    return rs_dict\n",
        "\n",
        "# Call lists2dict: rs_fxn\n",
        "rs_fxn = lists2dict(feature_names,row_vals)\n",
        "\n",
        "# Print rs_fxn\n",
        "print(rs_fxn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DkzuNeHrJgqp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Using a list comprehension**\n",
        "\n",
        "This time, you're going to use the** lists2dict()** function you defined in the last exercise to turn a bunch of lists into a list of dictionaries with the help of a list comprehension.\n",
        "\n",
        "The lists2dict() function has already been preloaded, together with a couple of lists, **feature_names **and **row_lists**. feature_names contains the header names of the World Bank dataset and **row_lists **is a list of lists, where each sublist is a list of actual values of a row from the dataset.\n",
        "\n",
        "Your goal is to use a list comprehension to generate a list of dicts, where the keys are the header names and the values are the row entries."
      ]
    },
    {
      "metadata": {
        "id": "ljjnkZMBRwgW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Print the first two lists in row_lists\n",
        "print(row_lists[0])\n",
        "print(row_lists[1])\n",
        "\n",
        "# Turn list of lists into list of dicts: list_of_dicts\n",
        "list_of_dicts = [lists2dict(feature_names,sublist)for sublist in row_lists]\n",
        "\n",
        "# Print the first two dictionaries in list_of_dicts\n",
        "print(list_of_dicts[0])\n",
        "print(list_of_dicts[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "foKfLu8cR0z7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Turning this all into a DataFrame**\n",
        "\n",
        "You will now use of all these to convert the list of dictionaries into a pandas DataFrame. You will see how convenient it is to generate a DataFrame from dictionaries with the **DataFrame() **function from the pandas package.\n",
        "\n",
        "The lists2dict() function, feature_names list, and row_lists list have been preloaded for this exercise."
      ]
    },
    {
      "metadata": {
        "id": "F7uRJTZKR7k3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import the pandas package\n",
        "import pandas as pd\n",
        "\n",
        "# Turn list of lists into list of dicts: list_of_dicts\n",
        "list_of_dicts = [lists2dict(feature_names, sublist) for sublist in row_lists]\n",
        "\n",
        "# Turn list of dicts into a DataFrame: df\n",
        "df = pd.DataFrame(list_of_dicts)\n",
        "\n",
        "# Print the head of the DataFrame\n",
        "print(df.head())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pbRNYxyAST76",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Using Python generators for streaming data\n"
      ]
    },
    {
      "metadata": {
        "id": "l97mYvWRSY2V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Processing data in chunks **\n",
        "\n",
        "Sometimes, data sources can be so large in size that storing the entire dataset in memory becomes too resource-intensive. In this exercise, you will process the first 1000 rows of a file line by line, to create a dictionary of the counts of how many times each country appears in a column in the dataset."
      ]
    },
    {
      "metadata": {
        "id": "UV7H5VPLSxLb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Open a connection to the file\n",
        "with open('world_dev_ind.csv') as file:\n",
        "\n",
        "    # Skip the column names\n",
        "    file.readline()\n",
        "\n",
        "    # Initialize an empty dictionary: counts_dict\n",
        "    counts_dict = {}\n",
        "\n",
        "    # Process only the first 1000 rows\n",
        "    for j in range(0,1000):\n",
        "\n",
        "        # Split the current line into a list: line\n",
        "        line = file.readline().split(',')\n",
        "\n",
        "        # Get the value for the first column: first_col\n",
        "        first_col = line[0]\n",
        "\n",
        "        # If the column value is in the dict, increment its value\n",
        "        if first_col in counts_dict.keys():\n",
        "            counts_dict[first_col] += 1\n",
        "\n",
        "        # Else, add to the dict and set value to 1\n",
        "        else:\n",
        "            counts_dict[first_col] = 1\n",
        "\n",
        "# Print the resulting dictionary\n",
        "print(counts_dict)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aeBpwejlTjyt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Writing a generator to load data in chunks **\n",
        "\n",
        "In the previous exercise, you processed a file line by line for a given number of lines. What if, however, you want to do this for the entire file?\n",
        "\n",
        "In this case, it would be useful to use **generators**. Generators allow users to **lazily evaluate** data. This concept of lazy evaluation is useful when you have to deal with very large datasets because it lets you generate values in an efficient manner by yielding only chunks of data at a time instead of the whole thing at once.\n",
        "\n",
        "In this exercise, you will define a generator function read_large_file() that produces a generator object which yields a single line from a file each time next() is called on it. "
      ]
    },
    {
      "metadata": {
        "id": "fABPe-G3TqGJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define read_large_file()\n",
        "def read_large_file(file_object):\n",
        "    \"\"\"A generator function to read a large file lazily.\"\"\"\n",
        "\n",
        "    # Loop indefinitely until the end of the file\n",
        "    while True:\n",
        "\n",
        "        # Read a line from the file: data\n",
        "        data = file_object.readline()\n",
        "        \n",
        "        # Break if this is the end of the file\n",
        "        if not data:\n",
        "            break\n",
        "\n",
        "        # Yield the line of data\n",
        "        yield data\n",
        "        \n",
        "# Open a connection to the file\n",
        "with open('world_dev_ind.csv') as file:\n",
        "\n",
        "    # Create a generator object for the file: gen_file\n",
        "    gen_file = (read_large_file(file))\n",
        "\n",
        "    # Print the first three lines of the file\n",
        "    print(next(gen_file))\n",
        "    print(next(gen_file))\n",
        "    print(next(gen_file))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NCa46VIHVID9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that since a file object is already a generator, you don't have to explicitly create a generator object with your **read_large_file() **function."
      ]
    },
    {
      "metadata": {
        "id": "QLdMi2nKVQq-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Writing a generator to load data in chunks**\n",
        "\n",
        "Now let's use your generator function to process the World Bank dataset like you did previously. You will process the file line by line, to create a dictionary of the counts of how many times each country appears in a column in the dataset. For this exercise, however, you won't process just 1000 rows of data, you'll process the entire dataset!"
      ]
    },
    {
      "metadata": {
        "id": "O3GYUkWBVHV_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initialize an empty dictionary: counts_dict\n",
        "counts_dict = {}\n",
        "\n",
        "# Open a connection to the file\n",
        "with open('world_dev_ind.csv') as file:\n",
        "\n",
        "    # Iterate over the generator from read_large_file()\n",
        "    for line in read_large_file(file):\n",
        "\n",
        "        row = line.split(',')\n",
        "        first_col = row[0]\n",
        "\n",
        "        if first_col in counts_dict.keys():\n",
        "            counts_dict[first_col] += 1\n",
        "        else:\n",
        "            counts_dict[first_col] = 1\n",
        "\n",
        "# Print            \n",
        "print(counts_dict)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KrywG75eV4Am",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Using pandas` read_csv iterator for streaming data"
      ]
    },
    {
      "metadata": {
        "id": "tx6ZgX_gWAOp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Writing an iterator to load data in chunks **\n",
        "\n",
        "Another way to read data too large to store in memory in chunks is to read the file in as DataFrames of a certain length, say, 100. For example, with the pandas package (imported as pd), you can do **pd.read_csv(filename, chunksize=100)**. This creates an iterable** reader objec**t, which means that you can use next() on it."
      ]
    },
    {
      "metadata": {
        "id": "7zfK8Y4zWSob",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import the pandas package\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize reader object: df_reader\n",
        "df_reader = pd.read_csv('ind_pop.csv', chunksize=10)\n",
        "\n",
        "# Print two chunks\n",
        "print(next(df_reader))\n",
        "print(next(df_reader))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IRoCwRA1WnOL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Writing an iterator to load data in chunks **\n",
        "\n",
        "In the previous exercise, you used read_csv() to read in DataFrame chunks from a large dataset. In this exercise, you will read in a file using a bigger DataFrame chunk size and then process the data from the first chunk.\n",
        "\n",
        "To process the data, you will create another DataFrame composed of only the rows from a specific country. You will then zip together two of the columns from the new DataFrame, **'Total Population' **and **'Urban population (% of total)'**. Finally, you will create a list of tuples from the zip object, where each tuple is composed of a value from each of the two columns mentioned."
      ]
    },
    {
      "metadata": {
        "id": "_DyF5OkRWzOk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initialize reader object: urb_pop_reader\n",
        "urb_pop_reader = pd.read_csv('ind_pop_data.csv', chunksize=1000)\n",
        "\n",
        "# Get the first DataFrame chunk: df_urb_pop\n",
        "df_urb_pop = next(urb_pop_reader)\n",
        "\n",
        "# Check out the head of the DataFrame\n",
        "print(df_urb_pop.head())\n",
        "\n",
        "# Check out specific country: df_pop_ceb\n",
        "df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode']=='CEB']\n",
        "\n",
        "# Zip DataFrame columns of interest: pops\n",
        "pops = zip(df_pop_ceb['Total Population'], df_pop_ceb['Urban population (% of total)'])\n",
        "\n",
        "# Turn zip object into list: pops_list\n",
        "pops_list = list(pops)\n",
        "\n",
        "# Print pops_list\n",
        "print(pops_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q8V6EgY5YGMR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Writing an iterator to load data in chunks **\n",
        "\n",
        "Starting from the code of the previous exercise, you will be using a list comprehension to create the values for a new column **'Total Urban Population' **from the list of tuples that you generated earlier. Recall from the previous exercise that the first and second elements of each tuple consist of, respectively, values from the columns **'Total Population'** and **'Urban population (% of total)'**. The values in this new column **'Total Urban Population',** therefore, are the product of the first and second element in each tuple. "
      ]
    },
    {
      "metadata": {
        "id": "TvwDHL59YhaM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Code from previous exercise\n",
        "urb_pop_reader = pd.read_csv('ind_pop_data.csv', chunksize=1000)\n",
        "df_urb_pop = next(urb_pop_reader)\n",
        "df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == 'CEB']\n",
        "pops = zip(df_pop_ceb['Total Population'], \n",
        "           df_pop_ceb['Urban population (% of total)'])\n",
        "pops_list = list(pops)\n",
        "\n",
        "# Use list comprehension to create new DataFrame column 'Total Urban Population'\n",
        "df_pop_ceb['Total Urban Population'] = [int (i *j *0.01) for i,j in pops_list ]\n",
        "\n",
        "# Plot urban population data\n",
        "df_pop_ceb.plot(kind='scatter', x='Year', y='Total Urban Population')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m3nFZemeaUFO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Writing an iterator to load data in chunks **\n",
        "\n",
        "This time, you will aggregate the results over all the DataFrame chunks in the dataset. This basically means you will be processing the entire dataset now. This is neat because you're going to be able to process the entire large dataset by just working on smaller pieces of it!"
      ]
    },
    {
      "metadata": {
        "id": "w5vC10Baacj2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initialize reader object: urb_pop_reader\n",
        "urb_pop_reader = pd.read_csv('ind_pop_data.csv', chunksize=1000)\n",
        "\n",
        "# Initialize empty DataFrame: data\n",
        "data = pd.DataFrame()\n",
        "\n",
        "# Iterate over each DataFrame chunk\n",
        "for df_urb_pop in urb_pop_reader:\n",
        "\n",
        "    # Check out specific country: df_pop_ceb\n",
        "    df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == 'CEB']\n",
        "\n",
        "    # Zip DataFrame columns of interest: pops\n",
        "    pops = zip(df_pop_ceb['Total Population'],\n",
        "                df_pop_ceb['Urban population (% of total)'])\n",
        "\n",
        "    # Turn zip object into list: pops_list\n",
        "    pops_list = list(pops)\n",
        "\n",
        "    # Use list comprehension to create new DataFrame column 'Total Urban Population'\n",
        "    df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
        "    \n",
        "    # Append DataFrame chunk to data: data\n",
        "    data = data.append(df_pop_ceb)\n",
        "\n",
        "# Plot urban population data\n",
        "data.plot(kind='scatter', x='Year', y='Total Urban Population')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PwAMvaaQbTXz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Writing an iterator to load data in chunks **\n",
        "\n",
        "In this last exercise, you will put all the code for processing the data into a single function so that you can reuse the code without having to rewrite the same things all over again.\n",
        "\n",
        "You're going to define the function **plot_pop()** which takes two arguments: the filename of the file to be processed, and the country code of the rows you want to process in the dataset.\n",
        "\n",
        "Because all of the previous code you've written in the previous exercises will be housed in **plot_pop()**, calling the function already does the following:\n",
        "*  Loading of the file chunk by chunk,\n",
        "*  Creating the new column of urban population values, and\n",
        "*  Plotting the urban population data.\n",
        "\n",
        "That's a lot of work, but the function now makes it convenient to repeat the same process for whatever file and country code you want to process and visualize!"
      ]
    },
    {
      "metadata": {
        "id": "vOOgpV4jbtq3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define plot_pop()\n",
        "def plot_pop(filename, country_code):\n",
        "\n",
        "    # Initialize reader object: urb_pop_reader\n",
        "    urb_pop_reader = pd.read_csv(filename, chunksize=1000)\n",
        "\n",
        "    # Initialize empty DataFrame: data\n",
        "    data = pd.DataFrame()\n",
        "    \n",
        "    # Iterate over each DataFrame chunk\n",
        "    for df_urb_pop in urb_pop_reader:\n",
        "        # Check out specific country: df_pop_ceb\n",
        "        df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == country_code]\n",
        "\n",
        "        # Zip DataFrame columns of interest: pops\n",
        "        pops = zip(df_pop_ceb['Total Population'],\n",
        "                    df_pop_ceb['Urban population (% of total)'])\n",
        "\n",
        "        # Turn zip object into list: pops_list\n",
        "        pops_list = list(pops)\n",
        "\n",
        "        # Use list comprehension to create new DataFrame column 'Total Urban Population'\n",
        "        df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
        "    \n",
        "        # Append DataFrame chunk to data: data\n",
        "        data = data.append(df_pop_ceb)\n",
        "\n",
        "    # Plot urban population data\n",
        "    data.plot(kind='scatter', x='Year', y='Total Urban Population')\n",
        "    plt.show()\n",
        "\n",
        "# Set the filename: fn\n",
        "fn = 'ind_pop_data.csv'\n",
        "\n",
        "# Call plot_pop for country code 'CEB'\n",
        "plot_pop('ind_pop_data.csv', 'CEB')\n",
        "\n",
        "# Call plot_pop for country code 'ARB'\n",
        "plot_pop('ind_pop_data.csv','ARB')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}